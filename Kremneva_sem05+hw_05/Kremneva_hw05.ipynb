{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "49240231-3107-4250-a39b-438a6d4b1182",
      "metadata": {
        "id": "49240231-3107-4250-a39b-438a6d4b1182"
      },
      "source": [
        "Для выполнения всех следующих задач вам необходимо выбрать два текстовых файла примерно одинаковой длины и похожего жанра на двух разных языках, будет неплохо, если это окажется один и тот же текст в переводе."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72179ba4-eb0c-400a-bbda-518afe58eb31",
      "metadata": {
        "id": "72179ba4-eb0c-400a-bbda-518afe58eb31"
      },
      "source": [
        "#### Задача 1.\n",
        "\n",
        "Просмотрите оба выбранных текста. Удостоверьтесь, что тексты чистые, если же в них есть какой-то мусор: хештеги, затесавшиеся при OCR символы и подобное, почистите с помощью регулярных выражений.\n",
        "\n",
        "Проведите первичный статистический анализ: разбейте тексты на предложения и на токены, посчитайте количество того и другого, сопоставьте. Какой текст оказался длиннее? В каком тексте средняя длина предложения больше? Почему? В каком тексте выше лексическое разнообразие?\n",
        "\n",
        "Таким образом, вам необходимо узнать следующие вещи:\n",
        "\n",
        "- количество предложений\n",
        "- количество токенов\n",
        "- средняя длина предложения (среднее количество слов в предложении)\n",
        "- соотношение \"уникальные токены / все токены\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e30172-4afa-4bba-8477-afb1599d9aed",
      "metadata": {
        "id": "15e30172-4afa-4bba-8477-afb1599d9aed"
      },
      "outputs": [],
      "source": [
        "!pip install stanza"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import stanza"
      ],
      "metadata": {
        "id": "odYEMAjLRsuc"
      },
      "id": "odYEMAjLRsuc",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/Dog_Star-Arthur_Clarke.txt', encoding='utf8') as f:\n",
        "    eng_text = f.read()\n",
        "\n",
        "with open('/content/Кларк Артур. Созвездие Пса.txt', encoding='windows-1251') as f:\n",
        "    rus_text = f.read()"
      ],
      "metadata": {
        "id": "B57T8UKwR9IA"
      },
      "id": "B57T8UKwR9IA",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nlp_ru = stanza.Pipeline(lang='ru', processors='tokenize,pos,lemma,depparse')\n",
        "nlp_en = stanza.Pipeline(lang='en', processors='tokenize,pos,lemma,depparse')"
      ],
      "metadata": {
        "id": "QGJbcNPDSjTu"
      },
      "id": "QGJbcNPDSjTu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def count_statistics(text):\n",
        "\n",
        "    if text == eng_text:\n",
        "        my_nlp = nlp_en\n",
        "    else:\n",
        "        my_nlp = nlp_ru\n",
        "\n",
        "    doc = my_nlp(text)\n",
        "\n",
        "    sentences_number = len(doc.sentences)\n",
        "    print(f'Кол-во предложений: {sentences_number}')\n",
        "\n",
        "    tokens_number = sum(len(sentence.tokens) for sentence in doc.sentences)\n",
        "    print(f'Кол-во токенов: {tokens_number}')\n",
        "\n",
        "    avg_sentence_length = tokens_number / sentences_number\n",
        "    print(f'Средняя длина предложения: {avg_sentence_length:.2f}')\n",
        "\n",
        "    # список уникальных токенов\n",
        "    unique_tokens = set([token.text for sentence in doc.sentences for token in sentence.tokens])\n",
        "    unique_all = len(unique_tokens) / tokens_number\n",
        "    print(f'Соотношение \"уникальные токены / все токены\": {unique_all:.2f}')"
      ],
      "metadata": {
        "id": "MnUPze5bTSZb"
      },
      "id": "MnUPze5bTSZb",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_statistics(eng_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su4zO2-4VOkm",
        "outputId": "2a089f9f-c2b5-4fb8-8854-9bf30792c509"
      },
      "id": "Su4zO2-4VOkm",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кол-во предложений: 89\n",
            "Кол-во токенов: 1837\n",
            "Средняя длина предложения: 20.64\n",
            "Соотношение \"уникальные токены / все токены\": 0.35\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_statistics(rus_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE85wqCKYxVD",
        "outputId": "d23c0b53-aa75-4443-a968-edb04db73754"
      },
      "id": "dE85wqCKYxVD",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Кол-во предложений: 133\n",
            "Кол-во токенов: 2140\n",
            "Средняя длина предложения: 16.09\n",
            "Соотношение \"уникальные токены / все токены\": 0.48\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Текст на русском длиннее.\n",
        "# Средняя длина предложения больше в тексте на английском. Видимо, используются более сложные предложения - они длиннее, но их меньше.\n",
        "# Лексическое разнообразие выше в русском тексте."
      ],
      "metadata": {
        "id": "HIHmjLF2ZTDV"
      },
      "id": "HIHmjLF2ZTDV",
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "55495b5e-b16b-4e09-916b-57c8d4c28501",
      "metadata": {
        "id": "55495b5e-b16b-4e09-916b-57c8d4c28501"
      },
      "source": [
        "#### Задача 2 (4 балла).\n",
        "\n",
        "Сделайте разборы ваших текстов в формате UD. Посчитайте, какой процент токенов по частям речи имеет совпадающие со словоформой леммы (т.е., в скольких случаях токены с частью речи VERB, например, имели словарную форму: и сам токен, и лемма одинаковые). Что вы можете сказать о выбранных вами языках на основании этих данных? Ожидаются две таблички с процентами совпадающих по лемме и токену слов для каждой части речи."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install prettytable"
      ],
      "metadata": {
        "id": "cGhoBiDw9PE2"
      },
      "id": "cGhoBiDw9PE2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from prettytable import PrettyTable"
      ],
      "metadata": {
        "id": "_cpUHhuJ9TkI"
      },
      "id": "_cpUHhuJ9TkI",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "d931898c-dd07-44ad-aa43-199dfd74ab41",
      "metadata": {
        "id": "d931898c-dd07-44ad-aa43-199dfd74ab41"
      },
      "outputs": [],
      "source": [
        "def token_is_lemma(text):\n",
        "\n",
        "    if text == eng_text:\n",
        "        my_nlp = nlp_en\n",
        "    else:\n",
        "        my_nlp = nlp_ru\n",
        "\n",
        "    doc = my_nlp(text)\n",
        "\n",
        "    d = {} # словарик типа {часть речи:кол-во совпадений леммы и словоформы}\n",
        "    for sentence in doc.sentences:\n",
        "        for word in sentence.words:\n",
        "            if word.text == word.lemma:\n",
        "                if word.upos in d.keys():\n",
        "                    d[word.upos] += 1\n",
        "                else:\n",
        "                    d[word.upos] = 1\n",
        "\n",
        "    tokens_number = sum(len(sentence.tokens) for sentence in doc.sentences)\n",
        "\n",
        "    # рисуем табличку\n",
        "    table = PrettyTable()\n",
        "    table.field_names = [\"POS\", \"percent\"]\n",
        "    for k, v in d.items():\n",
        "        percentage = v/tokens_number * 100\n",
        "        table.add_row([k, f'{round(percentage, 2)}%'])\n",
        "\n",
        "    return table"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(token_is_lemma(eng_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-wvDeiYI8Wgc",
        "outputId": "f450ccda-6c50-4306-c9fc-98e95e79b00e"
      },
      "id": "-wvDeiYI8Wgc",
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|  POS  | percent |\n",
            "+-------+---------+\n",
            "|  PRON |  10.51% |\n",
            "| PROPN |   2.5%  |\n",
            "|  PART |  2.12%  |\n",
            "|  ADJ  |  6.15%  |\n",
            "|  NOUN |  9.85%  |\n",
            "| PUNCT |  11.27% |\n",
            "|  ADP  |  9.64%  |\n",
            "| CCONJ |  2.78%  |\n",
            "|  ADV  |   6.1%  |\n",
            "|  DET  |  7.62%  |\n",
            "|  VERB |  3.97%  |\n",
            "| SCONJ |  2.29%  |\n",
            "|  AUX  |  2.07%  |\n",
            "|  NUM  |  0.71%  |\n",
            "|  INTJ |  0.05%  |\n",
            "|  SYM  |  0.11%  |\n",
            "+-------+---------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(token_is_lemma(rus_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m76Ihj0K8YZU",
        "outputId": "e8264b23-91c3-44c0-a2cd-a9e7301fcf79"
      },
      "id": "m76Ihj0K8YZU",
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+---------+\n",
            "|  POS  | percent |\n",
            "+-------+---------+\n",
            "|  NOUN |  5.14%  |\n",
            "|  ADP  |   6.4%  |\n",
            "|  ADJ  |  1.07%  |\n",
            "|  PART |   4.3%  |\n",
            "| PUNCT |  18.5%  |\n",
            "| CCONJ |   2.9%  |\n",
            "|  ADV  |  5.65%  |\n",
            "|  PRON |  4.91%  |\n",
            "|  VERB |  2.85%  |\n",
            "| SCONJ |  2.62%  |\n",
            "|  NUM  |  0.65%  |\n",
            "|  DET  |  0.56%  |\n",
            "| PROPN |  0.75%  |\n",
            "|  AUX  |  0.14%  |\n",
            "+-------+---------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# выводы логичные))\n",
        "\n",
        "# в английском чаще всего лемма и словоформа сопадают у неизменяемых частей речи\n",
        "# и у местоимений с сущ - в русском это в два раза реже из-за падежей\n",
        "\n",
        "# в русском вообще маленький разброс по процентам среди частей речи, т.к. почти все как-то да изменяется\n",
        "# чаще всего совпадают у неизменяемых частей речи\n",
        "\n",
        "# у глаголов в обоих языках маленький процент и разброс небольшой"
      ],
      "metadata": {
        "id": "IrSR7jKYIPI-"
      },
      "id": "IrSR7jKYIPI-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "f2cb9a33-9622-4199-9aad-576b9cb719ba",
      "metadata": {
        "id": "f2cb9a33-9622-4199-9aad-576b9cb719ba"
      },
      "source": [
        "#### Задача 3 (2 балла).\n",
        "\n",
        "Посчитайте медианную длину предложения для ваших текстов (медиана - это если взять все длины всех ваших предложений, упорядочить их от маленького к большому и выбрать то число, которое оказалось посередине, а если чисел четное количество, то взять среднее арифметическое двух чисел посередине. Например, если у вас пять предложений длинами 1, 2, 6, 7, 8, то медиана - 6, а если шесть предложений длинами 1, 1, 7, 9, 10, 11, то медиана - (7 + 9) / 2 = 8). Возьмите любые два предложения (на разных языках) и постройте для них деревья зависимостей. Изучите связи зависимостей (deprel) и вершины: согласны ли вы с разбором?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "id": "ce93167c-a0b1-4491-a6ad-5f567a2973eb",
      "metadata": {
        "id": "ce93167c-a0b1-4491-a6ad-5f567a2973eb"
      },
      "outputs": [],
      "source": [
        "def median_length(text):\n",
        "\n",
        "    if text == eng_text:\n",
        "        my_nlp = nlp_en\n",
        "    else:\n",
        "        my_nlp = nlp_ru\n",
        "\n",
        "    doc = my_nlp(text)\n",
        "\n",
        "    lengths = [] # здесь будем собирать длины предложений\n",
        "    for sentence in doc.sentences:\n",
        "        lengths.append(len(doc.sentences[0].tokens))\n",
        "\n",
        "    # сортируем длины\n",
        "    lengths.sort()\n",
        "\n",
        "    # вычисляем медиану\n",
        "    n = len(lengths)\n",
        "    if n % 2 == 0:\n",
        "        median = (lengths[n // 2 - 1] + lengths[n // 2]) / 2\n",
        "    else:\n",
        "        median = lengths[n // 2]\n",
        "\n",
        "    return median"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "median_length(eng_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvnJzr_6mBvS",
        "outputId": "2c74ec09-a297-4a73-df0c-b53190d87edc"
      },
      "id": "MvnJzr_6mBvS",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "median_length(rus_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uAnLdiBmDbZ",
        "outputId": "a008b3b4-f655-4de1-fad8-833e5ed9369f"
      },
      "id": "6uAnLdiBmDbZ",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dependency_tree(sentence):\n",
        "\n",
        "    if sentence[1] == 'ru':\n",
        "        doc = nlp_ru(sentence[0])\n",
        "    else:\n",
        "        doc = nlp_en(sentence[0])\n",
        "\n",
        "    print(*[f'id: {word.id}\\tword: {word.text}\\thead id: {word.head}\\thead: {sent.words[word.head-1].text if word.head > 0 else \"root\"}\\tdeprel: {word.deprel}' for sent in doc.sentences for word in sent.words], sep='\\n')\n"
      ],
      "metadata": {
        "id": "ZgxQ1yvJnDnX"
      },
      "id": "ZgxQ1yvJnDnX",
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dependency_tree(['She was a beautiful animal, about 95% Alsatian.', 'eng'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-HZ_2I8otDJ",
        "outputId": "daaa131e-f949-4fe6-ae9f-da7c90d4e15a"
      },
      "id": "s-HZ_2I8otDJ",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id: 1\tword: She\thead id: 5\thead: animal\tdeprel: nsubj\n",
            "id: 2\tword: was\thead id: 5\thead: animal\tdeprel: cop\n",
            "id: 3\tword: a\thead id: 5\thead: animal\tdeprel: det\n",
            "id: 4\tword: beautiful\thead id: 5\thead: animal\tdeprel: amod\n",
            "id: 5\tword: animal\thead id: 0\thead: root\tdeprel: root\n",
            "id: 6\tword: ,\thead id: 10\thead: Alsatian\tdeprel: punct\n",
            "id: 7\tword: about\thead id: 8\thead: 95\tdeprel: advmod\n",
            "id: 8\tword: 95\thead id: 9\thead: %\tdeprel: nummod\n",
            "id: 9\tword: %\thead id: 10\thead: Alsatian\tdeprel: compound\n",
            "id: 10\tword: Alsatian\thead id: 5\thead: animal\tdeprel: parataxis\n",
            "id: 11\tword: .\thead id: 5\thead: animal\tdeprel: punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dependency_tree(['Это было великолепное животное, почти чистокровная восточноевропейская овчарка.', 'ru'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6PBKo3iIoyji",
        "outputId": "8e3e94c5-727d-4ad6-d3dd-a565ec4f9aab"
      },
      "id": "6PBKo3iIoyji",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id: 1\tword: Это\thead id: 4\thead: животное\tdeprel: nsubj\n",
            "id: 2\tword: было\thead id: 4\thead: животное\tdeprel: cop\n",
            "id: 3\tword: великолепное\thead id: 4\thead: животное\tdeprel: amod\n",
            "id: 4\tword: животное\thead id: 0\thead: root\tdeprel: root\n",
            "id: 5\tword: ,\thead id: 9\thead: овчарка\tdeprel: punct\n",
            "id: 6\tword: почти\thead id: 7\thead: чистокровная\tdeprel: obl\n",
            "id: 7\tword: чистокровная\thead id: 9\thead: овчарка\tdeprel: amod\n",
            "id: 8\tword: восточноевропейская\thead id: 9\thead: овчарка\tdeprel: amod\n",
            "id: 9\tword: овчарка\thead id: 4\thead: животное\tdeprel: conj\n",
            "id: 10\tword: .\thead id: 4\thead: животное\tdeprel: punct\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# будто все норм, кроме овчарки/Alsatian. Мне кажется, это скорее appos??"
      ],
      "metadata": {
        "id": "A6-6sZUSs0ne"
      },
      "id": "A6-6sZUSs0ne",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "e83b2561-9f2f-4bf8-89dd-3ec539f3455b",
      "metadata": {
        "id": "e83b2561-9f2f-4bf8-89dd-3ec539f3455b"
      },
      "source": [
        "#### Задача 4 (3 балла).\n",
        "\n",
        "Посчитайте частотные списки токенов для каждой категории связей зависимостей (т.е., нужно выделить все токены в тексте, которые получали, например, ярлык amod, и посчитать их частоты). Выведите по первые три самых частотных токена для каждой категории (punct можно не выводить)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "ce753981-ffa2-4065-914c-e30bb9905f8e",
      "metadata": {
        "id": "ce753981-ffa2-4065-914c-e30bb9905f8e"
      },
      "outputs": [],
      "source": [
        "def pos_statistics(text):\n",
        "\n",
        "    if text == eng_text:\n",
        "        my_nlp = nlp_en\n",
        "    else:\n",
        "        my_nlp = nlp_ru\n",
        "\n",
        "    doc = my_nlp(text)\n",
        "\n",
        "    d = {} # словарик типа {категория связей зависимости:[токены]}\n",
        "    for sentence in doc.sentences:\n",
        "        for word in sentence.words:\n",
        "            if word.upos != 'PUNCT':\n",
        "                if word.deprel in d.keys():\n",
        "                    d[word.deprel].append(word.text)\n",
        "                else:\n",
        "                    d[word.deprel] = []\n",
        "                    d[word.deprel].append(word.text)\n",
        "\n",
        "    return d"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter"
      ],
      "metadata": {
        "id": "lc18bJwXfDBc"
      },
      "id": "lc18bJwXfDBc",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_stats = pos_statistics(eng_text)\n",
        "\n",
        "for k, v in eng_stats.items():\n",
        "    eng_counter = dict(Counter(v))\n",
        "    eng_tokens = list(eng_counter.keys())\n",
        "    print(f'{k}: {eng_tokens[0:3]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01gDJCvPdYaH",
        "outputId": "0bfb282d-b3ba-4bd1-b2f9-681b37c21957"
      },
      "id": "01gDJCvPdYaH",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "advmod: ['When', 'sleepily', 'only']\n",
            "nsubj: ['I', 'reaction', 'you']\n",
            "advcl: ['heard', 'separated', 'overwhelmed']\n",
            "nmod:poss: ['Laika', 'my', 'your']\n",
            "case: [\"'s\", 'in', 'of']\n",
            "amod: ['frantic', 'first', 'silly']\n",
            "obj: ['barking', 'fraction', 'eyes']\n",
            "cop: ['was', 'being', 'be']\n",
            "root: ['annoyance', 'turned', 'lasted']\n",
            "compound:prt: ['over', 'up', 'out']\n",
            "obl: ['bed', 'it', 'moment']\n",
            "cc: ['and', 'But', 'but']\n",
            "conj: ['muttered', 'fear', 'more']\n",
            "parataxis: ['Shut', 'bitch', 'returned']\n",
            "det: ['a', 'no', 'this']\n",
            "nmod: ['second', 'loneliness', 'million']\n",
            "mark: ['of', 'that', 'to']\n",
            "acl: ['going', 'cause', 'uttering']\n",
            "xcomp: ['mad', 'open', 'return']\n",
            "aux: ['did', 'might', 'had']\n",
            "acl:relcl: ['see', 'comes', 'living']\n",
            "iobj: ['me', 'myself', 'her']\n",
            "ccomp: ['set', 'dreaming', 'had']\n",
            "nsubj:pass: ['Laika', 'that', 'I']\n",
            "aux:pass: ['was', 'be', 'been']\n",
            "compound: ['quarter', 'fool', 'Observatory']\n",
            "obl:agent: ['miles', 'sadness', 'barking']\n",
            "nummod: ['five', 'one', '95']\n",
            "fixed: ['course', 'of', 'than']\n",
            "csubj: ['wished', 'leave', 'believe']\n",
            "nsubj:outer: ['It', 'I']\n",
            "appos: ['ball', 'one']\n",
            "obl:unmarked: ['evening', 'time', 'tonight']\n",
            "expl: ['it', 'There', 'there']\n",
            "det:predet: ['such', 'all']\n",
            "discourse: ['well']\n",
            "flat: ['Anderson', 'Francisco']\n",
            "advcl:relcl: ['became', 'died']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rus_stats = pos_statistics(rus_text)\n",
        "\n",
        "for k, v in rus_stats.items():\n",
        "    rus_counter = dict(Counter(v))\n",
        "    rus_tokens = list(rus_counter.keys())\n",
        "    print(f'{k}: {rus_tokens[0:3]}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7hO1fmkgda9x",
        "outputId": "1d9677b3-71a5-4313-ec8a-2541383d069f"
      },
      "id": "7hO1fmkgda9x",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "amod: ['Неистовый', 'первый', 'другой']\n",
            "nsubj: ['лай', 'Я', 'дремота']\n",
            "case: ['в', 'на', 'с']\n",
            "obl: ['миг', 'бок', 'ним']\n",
            "advmod: ['только', 'сонно', 'лишь']\n",
            "root: ['раздосадовал', 'повернулся', 'Замолчи']\n",
            "obj: ['меня', 'долю', 'глаза']\n",
            "cc: ['и', 'Но', 'а']\n",
            "conj: ['буркнул', 'очнулся', 'вернулось']\n",
            "vocative: ['собака', 'Лайка']\n",
            "nmod: ['секунды', 'одиночества', 'безумия']\n",
            "xcomp: ['открыть', 'увидеть', 'уснуть']\n",
            "iobj: ['мне', 'Тебе', 'себе']\n",
            "mark: ['что', 'когда', 'хотя']\n",
            "nummod: ['одна', 'миллиона', 'несколько']\n",
            "ccomp: ['ступала', 'устоял', 'нет']\n",
            "det: ['этого', 'своими', 'тот']\n",
            "parataxis: ['четверть', 'сказал', 'Разумеется']\n",
            "nummod:gov: ['пять', 'сколько', 'две']\n",
            "cop: ['будь', 'было', 'был']\n",
            "acl:relcl: ['увидишь', 'овладевает', 'провел']\n",
            "nsubj:pass: ['дверь', 'сон', 'животные']\n",
            "advcl: ['сменяется', 'хотелось', 'ища']\n",
            "aux:pass: ['был', 'было']\n",
            "fixed: ['и', 'конце', 'концов']\n",
            "csubj: ['установить', 'бросить', 'провести']\n",
            "discourse: ['то']\n",
            "appos: ['Лайка', 'Андерсон', 'Фарсайда']\n",
            "compound: ['дымчато']\n",
            "acl: ['поехал', 'было', 'сочли']\n",
            "aux: ['бы']\n",
            "obl:tmod: ['дней']\n",
            "csubj:pass: ['преодолеть']\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}